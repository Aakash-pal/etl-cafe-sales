# â˜• SQL Enhancement â€“ Intelligent Data Cleaning & Transformation

![Architecture Diagram](./data_architecture_cafe_sales.png)

> **Part of the Modular CafÃ© Sales ETL Project** â€“ This module focuses exclusively on deep cleaning and intelligent data inference using **pure SQL** with PostgreSQL CTEs.

---

## ğŸ“Œ Overview
The **SQL Enhancement** module demonstrates advanced SQL transformation logic applied to real-world, messy cafÃ© sales data.  
Instead of simply nullifying dirty values, this stage infers missing or incorrect fields using contextual rules â€” for example, deducing missing `item` names from `price_per_unit` and `location`.

This work forms the **core business logic** of the pipeline before analysis and visualization.

---

## ğŸš€ Features
- Cleans and standardizes raw transactional data.
- Uses **multi-step CTE chains** for logical transformations.
- Infers:
  - **Quantity** when `price_per_unit` and `total_spent` are known.
  - **Price per unit** when `quantity` and `total_spent` are known.
  - **Item name** using `cleaned_price` and `location` mapping rules.
  - **Location** and **payment method** from inferred product details.
- Ensures data types and formats are correct for analysis.

---

## ğŸ› ï¸ Tech Stack

| Tool / Technology | Purpose |
|-------------------|---------|
| **PostgreSQL** | Data storage and SQL transformations |
| **CTEs (Common Table Expressions)** | Step-by-step cleaning and inference |
| **Docker** | Containerized PostgreSQL environment |
| **Airflow** | Current standard for orchestration (Python-based trigger for SQL scripts) |
| **Python (Archived Script)** | Original orchestration method before Airflow |

---

## ğŸ“‚ Folder Structure
SQL_Enhancement/
â”‚
â”œâ”€â”€ README.md â†’ This file
â”œâ”€â”€ data_architecture_cafe_sales.png â†’ Visual overview of the SQL cleaning flow
â”œâ”€â”€ power_bi/ â†’ Power BI dashboard using cleaned dataset
â””â”€â”€ *.sql â†’ SQL scripts for table creation, cleaning, and validation


---

## ğŸ”„ Workflow
1. **Raw Table Creation** â€“ Imports data exactly as it appears in CSV.
2. **Staging Table Creation** â€“ Applies cleaning and inference logic using chained CTEs.
3. **Validation Queries** â€“ Ensures cleaned dataset meets quality standards.
4. **Downstream Use** â€“ Staging table becomes the input for Power BI dashboards.

---

ğŸ“† Project Timeline & Tasks
Week	Task	Status
|------|-------------------------------------------------------------- |---------|
|Week 1|	Create raw_cafe_sales table & import dirty_cafe_sales.csv  |	âœ… Completed|
|Week 2|	Introduce staging table with contextual repair logic       |	âœ… Completed|
|Week 3|	Implement advanced CTE cleaning logic for item, location, and payment_method|	âœ… Completed|
|Week 4|	Validate transformations via SQL queries                   |	âœ… Completed|
|Week 5|	Document enhancements & prepare for integration with Airflow|	âœ… Completed|

---

## ğŸ“œ Changelog
| Date       | Change |
|------------|--------|
| 2025-07-08 | Initial creation of SQL-only ETL project |
| 2025-07-10 | Added intelligent item inference rules |
| 2025-08-06 | Integrated with Apache Airflow for orchestration |
| 2025-08-08 | README updated for portfolio-ready format |

---

## ğŸ”— Related Modules
- [Main ETL Project Overview](../README.md)
- [Power BI Dashboard](./power_bi/)

---

## ğŸ“Œ Notes
- The **Python script version** of this transformation is archived in `cafe-sales-etl/scripts/archived/` and replaced by Airflow-triggered SQL execution.
- Test transaction `TXN_9999999` was used to validate inference logic in live runs.

---

## ğŸ“Š Final Results After Cleaning

| Field            | Null Rows |
|------------------|-----------|
| `item`           | 6         |
| `quantity`       | 38        |
| `price_per_unit` | 38        |
| `total_spent`    | 40        |
| `location`       | 3         |
| `payment_method` | 3         |

This represents a **massive reduction** in null countsâ€”especially for fields that were previously over 100 nulls. Most remaining nulls represent truly unrecoverable or ambiguous rows, which were intentionally left untouched to avoid risky assumptions.

---
## ğŸ™Œ Inspiration

Inspired by real-world messy datasets and the joys of solving puzzles with SQL. This solution provides a scalable template for contextual data repair tasks where values can be imputed logically from surrounding patterns.

---

## ğŸ“£ Feedback & Collaboration

Feel free to fork the repo, suggest improvements, add new rules, or use this as a base for your own data cleaning adventures. Contributions and ideas welcome!

